{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este exemplo, usamos o conjunto de dados providos pela Huawei\n",
    "\n",
    "Usaremos as bibliotecas matemática padrão do Python (math) e a Numpy, além de Pandas para plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do conjunto de dados utilizado e o tipo de algoritmo,\n",
    "seguido da impressão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Outlook Temp. Humidity    Wind Decision\n0     Sunny   Hot     High    Weak       No\n1     Sunny   Hot     High  Strong       No\n2  Overcast   Hot     High    Weak      Yes\n3      Rain  Mild     High    Weak      Yes\n4      Rain  Cool   Normal    Weak      Yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outlook</th>\n      <th>Temp.</th>\n      <th>Humidity</th>\n      <th>Wind</th>\n      <th>Decision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sunny</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sunny</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Strong</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Overcast</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rain</td>\n      <td>Mild</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rain</td>\n      <td>Cool</td>\n      <td>Normal</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithms = [\"Classification\", \"Regression\"]\n",
    "algorithm = algorithms[0]\n",
    "\n",
    "# Dataset1: Text features and text labels (golf.txt)\n",
    "# Dataset2: Mix features and Numeric labels, here you have to change the path to yours.\n",
    "datasets = [\"arvoresDeDecisao/golf.txt\", \"arvoresDeDecisao/golf4.txt\"]\n",
    "dataset = pd.read_csv(datasets[0])  # (0,0), (0,1), (1,1)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isto, são verificados os tipos de dados, para identificar se serão tratados como valores discretos (rótulos) ou contínuos (números)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Outlook': dtype('O'),\n 'Temp.': dtype('O'),\n 'Humidity': dtype('O'),\n 'Wind': dtype('O')}"
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dictionary is used to store feature types of continuous numeric features and discrete literal features for subsequent judgment\n",
    "dataset_features = dict()\n",
    "num_of_columns = dataset.shape[1] - 1\n",
    "#The data type of each column of the data is saved for displaying the data name\n",
    "for i in range(0, num_of_columns):\n",
    "    #Gets the column name and holds the characteristics of a column of data by column\n",
    "    column_name = dataset.columns[i]\n",
    "    #Save the type of the data\n",
    "    dataset_features[column_name] = dataset[column_name].dtypes\n",
    "\n",
    "dataset_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checagem do tipo de dados e compatibilidade com algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If the algorithm selects a regression tree but the label is not a continuous value, an error is\n",
    "#reported\n",
    "if algorithm == 'Regression':\n",
    "    if dataset['Decision'].dtypes == 'object':\n",
    "        raise ValueError('dataset wrong')\n",
    "# If the tag value is continuous, the regression tree must be used\n",
    "if dataset['Decision'].dtypes != 'object':\n",
    "    algorithm = 'Regression'\n",
    "    global_stdev = dataset['Decision'].std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento de atributos ou características contínuas.\n",
    "É calculado a função de distribuição acumulada dos valores entrados,\n",
    "e a frequência dos valores são divididas em duas partes,\n",
    "maior ou menor igual que um limiar, que são utilizados como rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This function is used to handle numeric characteristics\n",
    "def processContinuousFeatures(cdf, column_name):\n",
    "    # Numerical features are arranged in order\n",
    "    unique_values = sorted(cdf[column_name].unique())\n",
    "    subset_ginis = []\n",
    "    subset_red_stdevs = []\n",
    "    for i in range(0, len(unique_values) - 1):\n",
    "        threshold = unique_values[i]\n",
    "        # Find the segmentation result if the first number is used as the threshold\n",
    "        subset1 = cdf[cdf[column_name] <= threshold]\n",
    "        subset2 = cdf[cdf[column_name] > threshold]\n",
    "        # Calculate the proportion occupied by dividing the two parts\n",
    "        subset1_rows = subset1.shape[0]\n",
    "        subset2_rows = subset2.shape[0]\n",
    "        total_instances = cdf.shape[0]\n",
    "        # In the text feature part, entropy is calculated by using the cycle,\n",
    "        # and in the numeric part, entropy is calculated by using the two groups after segmentation,\n",
    "        # and the degree of entropy reduction is obtained\n",
    "        if algorithm == 'Classification':\n",
    "            decision_for_subset1, decision_for_subset2 = map(lambda x: x.value_counts.tolist(),\n",
    "                                                             [subset1['Decision'], subset2['Decision']])\n",
    "            gini_subset1, gini_subset2 = 1, 1\n",
    "            for j in range(0, len(decision_for_subset1)):\n",
    "                gini_subset1 = gini_subset1 - math.pow((decision_for_subset1[j] / subset1_rows), 2)\n",
    "            for j in range(0, len(decision_for_subset2)):\n",
    "                gini_subset2 = gini_subset2 - math.pow((decision_for_subset2[j] / subset2_rows), 2)\n",
    "            gini = (subset1_rows / total_instances) * gini_subset1 + (subset2_rows / total_instances) * gini_subset2\n",
    "            subset_ginis.append(gini)\n",
    "            # Take standard deviation as the judgment basis, calculate the decrease value of standard deviation at this time\n",
    "        elif algorithm == 'Regression':\n",
    "            superset_stdev = cdf['Decision'].std(ddof=0)\n",
    "            subset1_stdev = subset1['Decision'].std(ddof=0)\n",
    "            subset2_stdev = subset2['Decision'].std(ddof=0)\n",
    "            threshold_weighted_stdev = (subset1_rows / total_instances) * subset1_stdev + (\n",
    "                    subset2_rows / total_instances) * subset2_stdev\n",
    "            threshold_reducted_stdev = superset_stdev - threshold_weighted_stdev\n",
    "            subset_red_stdevs.append(threshold_reducted_stdev)\n",
    "    #Find the index of the split value\n",
    "    if algorithm == \"Classification\":\n",
    "        winner_one = subset_ginis.index(min(subset_ginis))\n",
    "    elif algorithm == \"Regression\":\n",
    "        winner_one = subset_red_stdevs.index(max(subset_red_stdevs))\n",
    "    # Find the corresponding value according to the index\n",
    "    winner_threshold = unique_values[winner_one]\n",
    "    # Converts the original data column to an edited string column.\n",
    "    # Characters smaller than the threshold are modified with the <= threshold value\n",
    "    cdf[column_name] = np.where(cdf[column_name] <= winner_threshold, \"<=\" + str(winner_threshold),\n",
    "                                \">\" + str(winner_threshold))\n",
    "    return cdf\n",
    "\n",
    "\n",
    "dataset_clone = dataset.copy(deep=True)\n",
    "\n",
    "try:\n",
    "    processContinuousFeatures(dataset_clone, \"Temp.\")\n",
    "    print(\"Before:\\n\", dataset.head())\n",
    "    plt.hist(set(dataset[\"Temp.\"].values), density=True, range=(60, 90), bins=20)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(\"Temperature [F]\")\n",
    "    print(\"\\n\\nAfter:\\n\", dataset_clone.head())\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos meios de se identificar que atributos/features são mais relevantes para a decisão final é\n",
    "o cálculo do ganho de informação, que se baseia na entropia dos dados.\n",
    "\n",
    "\n",
    "Se temos um atributo composto de duas classes (e.g. a coluna 'Decision' pode assumir os valores 'Yes' e 'No),\n",
    "a entropia deste atributo é dada pela seguinte fórmula\n",
    "\n",
    "$p_{yes} = \\frac{\\#YesDecisions}{\\#TotalDecisions}$\n",
    "\n",
    "$p_{no} = \\frac{\\#NoDecisions}{\\#TotalDecisions}$\n",
    "\n",
    "$E(Decision) = - p_{yes} * log_2(p_{yes}) - p_{no}*log_2(p_{no})$\n",
    "\n",
    "Quando calculamos para o dataset atual, encontramos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E(Decision) = 0.940286\n"
     ]
    }
   ],
   "source": [
    "# This function calculates the entropy of the column, and the input data must contain the Decision\n",
    "# column\n",
    "def calculateEntropy(dataset):\n",
    "    # The regression tree entropy is 0\n",
    "    if algorithm == 'Regression':\n",
    "        return 0\n",
    "\n",
    "    rows = dataset.shape[0]\n",
    "    # Use Value_counts to get all values stored as dictionaries, keys: finds keys, and Tolist: change to lists.\n",
    "    # This line of code finds the tag value.\n",
    "    decisions = dataset['Decision'].value_counts().keys().tolist()\n",
    "    entropy = 0\n",
    "    # Here the loop traverses all the tags\n",
    "    for i in range(0, len(decisions)):\n",
    "        # Record the number of times the tag value appears\n",
    "        num_of_decisions = dataset['Decision'].value_counts().tolist()[i]\n",
    "        # probability of occurrence\n",
    "        class_probability = num_of_decisions / rows\n",
    "        # Calculate the entropy and sum it up\n",
    "        entropy = entropy - class_probability * math.log(class_probability, 2)\n",
    "    return entropy\n",
    "\n",
    "if algorithm != 'Regression':\n",
    "    entropy = calculateEntropy(dataset)\n",
    "    print(\"E(Decision) = %f\" % entropy)\n",
    "else:\n",
    "    print(\"Make sure to use Classification Algorithm and dataset golf.txt to print the entropy results\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para calcularmos o ganho de informação de cada coluna, precisamos calcular contribuição\n",
    "das entropias de cada uma das classes/valores que um atributo/coluna pode assumir.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [
    {
     "data": {
      "text/plain": "    Outlook Temp. Humidity    Wind Decision\n0     Sunny   Hot     High    Weak       No\n1     Sunny   Hot     High  Strong       No\n2  Overcast   Hot     High    Weak      Yes\n3      Rain  Mild     High    Weak      Yes\n4      Rain  Cool   Normal    Weak      Yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outlook</th>\n      <th>Temp.</th>\n      <th>Humidity</th>\n      <th>Wind</th>\n      <th>Decision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sunny</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sunny</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Strong</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Overcast</td>\n      <td>Hot</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rain</td>\n      <td>Mild</td>\n      <td>High</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rain</td>\n      <td>Cool</td>\n      <td>Normal</td>\n      <td>Weak</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Por exemplo, para Outlook mostrado acima teremos:\n",
    "\n",
    "$E(Sunny) = -\\frac{0}{2}*log_{2}(\\frac{0}{2})-\\frac{2}{2}*log_{2}(\\frac{2}{2})$\\\n",
    "\n",
    "$E(Rain) = -\\frac{2}{2}*log_{2}(\\frac{2}{2})-\\frac{0}{2}*log_{2}(\\frac{0}{2})$\\\n",
    "\n",
    "$E(Outcast) = -\\frac{1}{1}*log_{2}(\\frac{1}{1})-\\frac{0}{1}*log_{2}(\\frac{0}{1})$\\\n",
    "\n",
    "$Gain(Outlook) = E(Decision) - \\frac{2}{5}*E(Sunny) - \\frac{2}{5}*E(Rain) - \\frac{1}{5}*E(Outcast)$\\"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains of information\n",
      "('Humidity', 0.17095059445466854)\n",
      "('Outlook', 0.9709505944546686)\n",
      "('Temp.', 0.4199730940219749)\n",
      "('Wind', 0.3219280948873623)\n"
     ]
    }
   ],
   "source": [
    "def demo_gain_of_information(dataset=dataset[:5]):\n",
    "    entropy = calculateEntropy(dataset)\n",
    "    columns = dataset.shape[1]\n",
    "    rows = dataset.shape[0]\n",
    "    gains_of_information = {}\n",
    "    # Traverse all columns and calculate the relevant indexes of all columns according to algorithm selection\n",
    "    for i in range(0, columns-1):\n",
    "        column_name = dataset.columns[i]\n",
    "        column_type = dataset[column_name].dtypes\n",
    "        classes = dataset[column_name].value_counts()\n",
    "        class_gain_of_information = entropy\n",
    "        # Start the loop with the type of data in the column\n",
    "        for j in range(0, len(classes)):\n",
    "            entropy_class = 0\n",
    "            current_class = classes.keys().tolist()[j]\n",
    "            # The final classification result corresponding to the data is selected\n",
    "            # by deleting the value of the dataset column equal to the current data\n",
    "            subdataset = dataset[dataset[column_name] == current_class]\n",
    "            subset_instances = subdataset.shape[0]\n",
    "            # The entropy of information is calculated here\n",
    "            if algorithm == 'Classification':\n",
    "                decision_list = subdataset['Decision'].value_counts().tolist()\n",
    "                # Gain of Information\n",
    "                # One of the possible scores to find out the most relevant column\n",
    "                # Calculate for each decision (e.g. Decision==Yes and Decision==No) of a given class (e.g. Outlook==Sunny)\n",
    "                for k in range(0, len(decision_list)):\n",
    "                    p_decision = decision_list[k]/subset_instances\n",
    "                    entropy_class -= math.log2(p_decision)*p_decision\n",
    "                # After calculating the entropy for each decision,\n",
    "                # we need to multiply by the frequency of the class (e.g. number of rows where Outlook==Sunny)\n",
    "                # divided by the total instances of a class\n",
    "                # (e.g. number of rows of Outlook, including Outlook==Sunny, Outlook==Rain, Outlook==Overcast)\n",
    "                class_gain_of_information -= entropy_class*(subset_instances/rows)\n",
    "            gains_of_information[column_name] = class_gain_of_information\n",
    "    return gains_of_information\n",
    "\n",
    "\n",
    "\n",
    "if algorithm != 'Regression':\n",
    "    gains_of_information = demo_gain_of_information()\n",
    "    print(\"Gains of information\",*list(sorted(gains_of_information.items())), sep=\"\\n\")\n",
    "else:\n",
    "    print(\"Make sure to use Classification Algorithm and dataset golf.txt to print the entropy results\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando as contas acima para cada um dos atributos/colunas, encontramos que o atributo\n",
    "que contribui majoritariamente para a decisão final é a coluna de Outlook.\n",
    "\n",
    "Existem outros métodos para esta escolha (estão implementados GINI para o caso de classificação, e desvio padrão para o caso de regressão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest contributor for the final decision: Outlook\n"
     ]
    }
   ],
   "source": [
    "# The main purpose of this function is to traverse the entire column of the table,\n",
    "# find which column is the best split column, and return the name of the column\n",
    "def findDecision(ddf):\n",
    "    # If it's a regression tree, then you take the standard deviation of the true value\n",
    "    if algorithm == 'Regression':\n",
    "        stdev = ddf['Decision'].std(ddof=0)\n",
    "    # Get the entropy of the decision column\n",
    "    entropy = calculateEntropy(ddf)\n",
    "    columns = ddf.shape[1]\n",
    "    rows = ddf.shape[0]\n",
    "    # Used to store Gini and standard deviation values\n",
    "    ginis = []\n",
    "    reducted_stdevs = []\n",
    "    gains = []\n",
    "    # Traverse all columns and calculate the relevant indexes of all columns according to algorithm selection\n",
    "    for i in range(0, columns-1):\n",
    "        column_name = ddf.columns[i]\n",
    "        column_type = ddf[column_name].dtypes\n",
    "        # Determine if the column feature is a number, and if so, process the data using the\n",
    "        #following function, which modifies the data to a string type category on return.\n",
    "        # The idea is to directly use character characteristics, continuous digital characteristics into\n",
    "        #discrete character characteristics\n",
    "        if column_type != 'object':\n",
    "            ddf = processContinuousFeatures(ddf, column_name)\n",
    "        # The statistical data in this column can be obtained, and the continuous data can be\n",
    "        # directly classified after processing, and the categories are less than the threshold\n",
    "        # and greater than the threshold\n",
    "        classes = ddf[column_name].value_counts()\n",
    "        gini = 0\n",
    "        weighted_stdev = 0\n",
    "        # Start the loop with the type of data in the column\n",
    "        for j in range(0, len(classes)):\n",
    "            gain = 0\n",
    "            current_class = classes.keys().tolist()[j]\n",
    "            # The final classification result corresponding to the data is selected\n",
    "            # by deleting the value of the dataset column equal to the current data\n",
    "            subdataset = ddf[ddf[column_name] == current_class]\n",
    "            subset_instances = subdataset.shape[0]\n",
    "            # The entropy of information is calculated here\n",
    "            if algorithm == 'Classification':\n",
    "                # GINI index\n",
    "                # One of the possible scores to find out the most relevant column\n",
    "                decision_list = subdataset['Decision'].value_counts().tolist()\n",
    "                subgini = 1\n",
    "                for k in range(0, len(decision_list)):\n",
    "                    subgini = subgini - math.pow((decision_list[k] / subset_instances), 2)\n",
    "                gini = gini + (subset_instances / rows) * subgini\n",
    "\n",
    "                # Gain of Information\n",
    "                # One of the possible scores to find out the most relevant column\n",
    "                # Calculate for each decision (e.g. Decision==Yes and Decision==No) of a given class (e.g. Outlook==Sunny)\n",
    "                for k in range(0, len(decision_list)):\n",
    "                    p_decision = decision_list[k]/subset_instances\n",
    "                    gain -= math.log2(p_decision)*p_decision\n",
    "                # After calculating the entropy for each decision,\n",
    "                # we need to multiply by the frequency of the class (e.g. number of rows where Outlook==Sunny)\n",
    "                # divided by the total instances of a class\n",
    "                # (e.g. number of rows of Outlook, including Outlook==Sunny, Outlook==Rain, Outlook==Overcast)\n",
    "                gain *= (subset_instances/rows)\n",
    "\n",
    "                # Then we subtract the calculated entropy from the total entropy to find the gain of information\n",
    "                gain = entropy - gain\n",
    "            # The regression tree is judged by the standard deviation,\n",
    "            # and the standard deviation of the subclasses in this column is calculated here\n",
    "            elif algorithm == 'Regression':\n",
    "                subset_stdev = subdataset['Decision'].std(ddof=0)\n",
    "                weighted_stdev = weighted_stdev + (subset_instances / rows) * subset_stdev\n",
    "        # Used to store the final value of this column\n",
    "        if algorithm == \"Classification\":\n",
    "            ginis.append((i, gini))\n",
    "            gains.append((i, gain))\n",
    "            # Store the decrease in standard deviation for all columns\n",
    "        elif algorithm == 'Regression':\n",
    "            reducted_stdev = stdev - weighted_stdev\n",
    "            reducted_stdevs.append(reducted_stdev)\n",
    "            #print(column_name, current_class, reducted_stdev)\n",
    "    # Determine which column is the first branch\n",
    "    # by selecting the index of the largest value from the list of evaluation indicators\n",
    "    if algorithm == \"Classification\":\n",
    "        # You can choose whether to use GINI Index or Gain of Information here\n",
    "\n",
    "        # Ginis is a list of tuples containing the largest contributor column and the contribution (lower number)\n",
    "        min_ginis = list(sorted(ginis, key=lambda x: x[1]))[0]\n",
    "        winner_index = min_ginis[0]  # get column\n",
    "\n",
    "        # Gain of informations is a list of tuples containing the largest contributor column and the contribution (higher number)\n",
    "        max_gain = list(sorted(gains, key=lambda x: x[1]))[-1]\n",
    "        winner_index = max_gain[0]\n",
    "    elif algorithm == \"Regression\":\n",
    "        #print(reducted_stdevs)\n",
    "        winner_index = reducted_stdevs.index(max(reducted_stdevs))\n",
    "    winner_name = ddf.columns[winner_index]\n",
    "    return winner_name\n",
    "\n",
    "\n",
    "dataset_clone = dataset.copy(deep=True)\n",
    "largest_contributor = findDecision(dataset_clone)\n",
    "print(\"Largest contributor for the final decision:\", largest_contributor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então começar a montar arvore de decisão recursivamente seguindo os passos:\n",
    " - encontrando o maior contribuidor\n",
    " - criando o nó para esse contribuidor\n",
    " - eliminando a coluna do maior contribuidor\n",
    " - montar a subarvore de decisão, desta vez sem a coluna do maior contribuidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " if  Outlook  == 'Sunny' :\n",
      "  if  Humidity  == 'High' :\n",
      "   return  'No'\n",
      "  if  Humidity  == 'Normal' :\n",
      "   return  'Yes'\n",
      " if  Outlook  == 'Rain' :\n",
      "  if  Wind  == 'Weak' :\n",
      "   return  'Yes'\n",
      "  if  Wind  == 'Strong' :\n",
      "   return  'No'\n",
      " if  Outlook  == 'Overcast' :\n",
      "  return  'Yes'\n"
     ]
    }
   ],
   "source": [
    "# With this function, you build the decision tree model,\n",
    "# entering data in dataframe format, the indentation value, and the file address\n",
    "# If the value in the column is literal, it branches directly by literal category\n",
    "def buildDecisionTree(dataset, indentation=0):\n",
    "    # Identify the different charForResp\n",
    "    charForResp = \"'\"\n",
    "    if algorithm == 'Regression':\n",
    "        charForResp = \"\"\n",
    "    tmp_indentation = indentation * 1\n",
    "    dataset_copy = dataset.copy(deep=True)\n",
    "    # Output the winning column of the decision tree, enter a list,\n",
    "    # and output the column name of the decision column in the list\n",
    "    winner_name = findDecision(dataset)\n",
    "    # Determines whether the winning column is a number or a character\n",
    "    numericColumn = False\n",
    "    if dataset_features[winner_name] != 'object':\n",
    "        numericColumn = True\n",
    "    # To ensure the integrity of the original data and prevent the data from changing,\n",
    "    # mainly to ensure that the data of other columns besides the winning column does not change,\n",
    "    # so as to continue the branch in the next step.\n",
    "    columns = dataset.shape[1]\n",
    "    for i in range(0, columns - 1):\n",
    "        column_name = dataset.columns[i]\n",
    "        if dataset[column_name].dtype != 'object' and column_name != winner_name:\n",
    "            dataset[column_name] = dataset_copy[column_name]\n",
    "    # Find the element in the branching column\n",
    "    classes = dataset[winner_name].value_counts().keys().tolist()\n",
    "    # Traversing all classes in the branch column has two functions:\n",
    "    # 1. Display which class is currently traversed to; 2. Determine whether the current class is\n",
    "    #already leaf node\n",
    "    for i in range(0, len(classes)):\n",
    "        # Find the Subdataset as in FindDecision, but discard this column of the current branch\n",
    "        current_class = classes[i]\n",
    "        subdataset = dataset[dataset[winner_name] == current_class]\n",
    "        # At the same time, the data of the first branch column is discarded and the remaining data\n",
    "        #is processed\n",
    "        subdataset = subdataset.drop(columns=[winner_name])\n",
    "        # Edit the display situation. If it is a numeric feature, the character conversion has been\n",
    "        #completed when searching for branches.\n",
    "        #If it is not a character feature, it is displayed with column names\n",
    "        if numericColumn == True:\n",
    "            compareTo = current_class  # current class might be <=x or >x in this case\n",
    "        else:\n",
    "            compareTo = \" == '\" + str(current_class) + \"'\"\n",
    "\n",
    "        terminateBuilding = False\n",
    "        # -----------------------------------------------\n",
    "        # This determines whether it is already the last leaf node\n",
    "        if len(subdataset['Decision'].value_counts().tolist()) == 1:\n",
    "            final_decision = subdataset['Decision'].value_counts().keys().tolist()[\n",
    "                0]  # all items are equal in this case\n",
    "            terminateBuilding = True\n",
    "        # At this time, only the Decision column is left, that is, all the segmentation features havebeen used\n",
    "        elif subdataset.shape[1] == 1:\n",
    "            # get the most frequent one\n",
    "            final_decision = subdataset['Decision'].value_counts().idxmax()\n",
    "            terminateBuilding = True\n",
    "        # The regression tree is judged as leaf node if the number of elements is less than 5\n",
    "        #elif algorithm == 'Regression' and subdataset.shape[0] < 5: # pruning condition\n",
    "        # Another criterion is to take the standard deviation as the criterion and the sample mean in\n",
    "        #the node as the value of the node\n",
    "        elif algorithm == 'Regression' and subdataset['Decision'].std(ddof=0) / global_stdev < 0.4:\n",
    "            # get average\n",
    "            final_decision = subdataset['Decision'].mean()\n",
    "            terminateBuilding = True\n",
    "\n",
    "        # indentation is a number used to generate ' ' to adjust the display format of the decision making process\n",
    "        def formatRule(indentation):\n",
    "            return '' + ' ' * indentation\n",
    "\n",
    "        # -----------------------------------------------\n",
    "        # Here we begin to output the branching results of the decision tree.。\n",
    "        print(formatRule(indentation), \"if \", winner_name, compareTo, \":\")\n",
    "        # -----------------------------------------------\n",
    "        # check decision is made\n",
    "        if terminateBuilding:\n",
    "            print(formatRule(indentation + 1), \"return \", charForResp + str(final_decision) + charForResp)\n",
    "        else:  # decision is not made, continue to create branch and leafs\n",
    "            # The size of the indent at display represented by indentation\n",
    "            indentation = indentation + 1\n",
    "            # Call this function again for the next loop\n",
    "            buildDecisionTree(subdataset, indentation)\n",
    "        indentation = tmp_indentation * 1\n",
    "\n",
    "\n",
    "# call the function\n",
    "buildDecisionTree(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}